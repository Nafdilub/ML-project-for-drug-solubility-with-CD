{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c55b4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2024.9.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from rdkit) (11.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from rdkit) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gagno\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting numpy>=1.19.5\n",
      "  Using cached numpy-1.24.4-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed numpy-1.24.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 2.1.1 requires sentencepiece, which is not installed.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.4 which is incompatible.\n",
      "lifelines 0.30.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\gagno\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: xgboost in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\gagno\\anaconda3\\lib\\site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b4f4dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'InconsistentVersionWarning' from 'sklearn.exceptions' (C:\\Users\\gagno\\anaconda3\\lib\\site-packages\\sklearn\\exceptions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23604\\811783597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'InconsistentVersionWarning' from 'sklearn.exceptions' (C:\\Users\\gagno\\anaconda3\\lib\\site-packages\\sklearn\\exceptions.py)"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f17590",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles('CCCC')\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b919d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                         Name  \\\n",
      "0     1         Ibuprofen / HP-B-CD   \n",
      "1     2      Dexamethasone / B - CD   \n",
      "2     3         Piroxicam / HP-B-CD   \n",
      "3     4    Hydrocortisone / HP-B-CD   \n",
      "4     5       Albendazole / RM-B-CD   \n",
      "5     6            Valtarsan / B-CD   \n",
      "6     7        Nifedipine / HP-B-CD   \n",
      "7     8        Nimodipine / HP-B-CD   \n",
      "8     9     Carbamazepine / HP-B-CD   \n",
      "9    10      Itraconazole / HP-B-CD   \n",
      "10   11       Simvastatin / HP-B-CD   \n",
      "11   12          Curcumin / HP-B-CD   \n",
      "12   13  Indomethacin / HP- B - CD    \n",
      "13   14     Naproxen / HP - B - CD    \n",
      "14   15        Diclofenac / HP-B-CD   \n",
      "15   16   Resveratrol / HP-Gamma CD   \n",
      "\n",
      "                                               Smiles MolWeight  LogP  \\\n",
      "0                          CC(C)Cc1ccc(cc1)C(C)C(=O)O   1606.29  3.84   \n",
      "1   CC(C)C1C(=O)CC2C(C1O)(CC(C1=CC(=O)C=C2C1(C)O)F...   1527.47  1.93   \n",
      "2                     CN1NS(=O)(=O)C2=C(O)C=CN=C2C1=O   1466.35  2.20   \n",
      "3              CC(=O)C1(CCC2C1(CCC1C(C2CC(C1O)O)O)C)O   1762.46  1.79   \n",
      "4                      CCCSC1=CC=C2C=C1N=C(C(=O)OC)N2   250.323  3.22   \n",
      "5   CC(C)C[C@H](C(=O)NCc1ccc(cc1)c1ccccc1C(=N)N=N)...    1570.5  3.68   \n",
      "6   CCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])C)...      1846  2.49   \n",
      "7   COCCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])...    418.44  3.41   \n",
      "8                        O=C1Nc2ccccc2C2=CC=CC=C2C1=O  1371.25   2.10   \n",
      "9   CC1=NC(C)=NC(OCC2CCC(OC3=NC(N4CCN(C)CC4)=NC(C4...    1840.6  5.48   \n",
      "10  CC(C)CC(CC=C)C(=O)OC[C@@H]1CC[C@@H](CC1)C(=O)O...   1553.55  4.51   \n",
      "11      COc1ccc(cc1)/C=C/C(=O)CC(=O)/C=C/c1ccc(cc1)OC   1503.36  3.62   \n",
      "12      COc1ccc2c(c1)n(c(c2C(=O)O)C(=O)c1ccc(cc1)Cl)C    1492.8  4.46   \n",
      "13                       COc1cc2ccc(C(C)C(=O)O)cc2cc1   1365.24  3.39   \n",
      "14                   OC(=O)Cc1cccc(c1)Nc1c(cccc1Cl)Cl   1431.15  4.75   \n",
      "15               OC1=CC=CC(/C=C/C2=CC(O)=CC(O)=C2)=C1  1728.247  2.57   \n",
      "\n",
      "    LogS (CD)  HPCalculated  Descriptors   \\\n",
      "0       -3.50           NaN           NaN   \n",
      "1       -2.98           NaN           NaN   \n",
      "2       -4.17           NaN           NaN   \n",
      "3       -1.83           NaN           NaN   \n",
      "4       -0.92           NaN           NaN   \n",
      "5       -2.92           NaN           NaN   \n",
      "6       -3.92           NaN           NaN   \n",
      "7       -3.88           NaN           NaN   \n",
      "8       -2.33           NaN           NaN   \n",
      "9       -4.83           NaN           NaN   \n",
      "10      -3.94           NaN           NaN   \n",
      "11      -4.09           NaN           NaN   \n",
      "12      -4.23           NaN           NaN   \n",
      "13      -1.75           NaN           NaN   \n",
      "14      -4.80           NaN           NaN   \n",
      "15      -3.20           NaN           NaN   \n",
      "\n",
      "    CD-complex solubility (mg/ml; unless stated otherwise)  \\\n",
      "0                                                 NaN        \n",
      "1                                            1.600000        \n",
      "2                                            0.100000        \n",
      "3                                           26.000000        \n",
      "4                                           30.000000        \n",
      "5                                            1.884600        \n",
      "6                                            0.224000        \n",
      "7                                            0.055000        \n",
      "8                                            6.390000        \n",
      "9                                            0.027000        \n",
      "10                                           0.180000        \n",
      "11                                           0.123600        \n",
      "12                                           0.088000        \n",
      "13                                          24.028224        \n",
      "14                                           0.022500        \n",
      "15                                           1.100000        \n",
      "\n",
      "    Intrinistic solubility (mg/ml; unless stated otherwise  Enhancement Factor  \n",
      "0                                                 NaN                30.000000  \n",
      "1                                            0.160000                10.000000  \n",
      "2                                            0.023000                 4.347826  \n",
      "3                                            0.280000                71.400000  \n",
      "4                                            0.010000               600.000000  \n",
      "5                                            0.003192               590.783000  \n",
      "6                                            0.005000                44.800000  \n",
      "7                                            0.002500                22.000000  \n",
      "8                                            0.140000                45.600000  \n",
      "9                                            0.000001             27000.000000  \n",
      "10                                           0.030000                 6.000000  \n",
      "11                                           0.000600               206.000000  \n",
      "12                                           0.008800                10.000000  \n",
      "13                                           0.115131               208.704900  \n",
      "14                                           0.003000                 7.500000  \n",
      "15                                           0.030000                36.666667  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[22:54:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "C:\\Users\\gagno\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Neural Network Model (Test Set) ===\n",
      "Architecture: hidden_layer_sizes=(16, 8), activation='relu'\n",
      "MSE  : 4468340.3518\n",
      "RMSE : 2113.8449\n",
      "MAE  : 1908.4113\n",
      "R²   : -71.0034\n",
      "Adjusted R²: nan\n",
      "\n",
      "=== Predict Enhancement Factor for a new SMILES ===\n",
      "Enter a SMILES string (or type 'quit' to exit): quit\n",
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RDKit for SMILES parsing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# For train-test split, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# For feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simple neural network regressor from scikit-learn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=2, n_bits=1024):\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to a Morgan fingerprint (ECFP) vector of length n_bits.\n",
    "    Returns a NumPy array of shape (n_bits,) or None if SMILES is invalid.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def main():\n",
    "    # 1. Load your CSV dataset (adjust filename/column names as needed)\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head(18))  # CSV should include 'Smiles' and 'Enhancement Factor'\n",
    "    \n",
    "    # 2. Basic cleaning: handle infinities and ensure 'Enhancement Factor' is numeric\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    \n",
    "    # Drop rows with missing values in 'Smiles' or 'Enhancement Factor'\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    # 3. Convert SMILES to numeric features (Morgan fingerprints)\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    enhancement_factors = df[\"Enhancement Factor\"].values\n",
    "    \n",
    "    X_fps = []\n",
    "    valid_y = []\n",
    "    for smi, val in zip(smiles_list, enhancement_factors):\n",
    "        fp = smiles_to_morgan_fp(smi, radius=2, n_bits=1024)\n",
    "        if fp is not None:\n",
    "            X_fps.append(fp)\n",
    "            valid_y.append(val)\n",
    "    \n",
    "    X = np.array(X_fps, dtype=float)\n",
    "    y = np.array(valid_y, dtype=float)\n",
    "    \n",
    "    # 4. Train-test split\n",
    "    #    We'll do 80-20 here, but with only 16 rows, consider cross-validation.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # 5. Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    \n",
    "    # 6. Define and train a neural network (MLPRegressor)\n",
    "    nn_model = MLPRegressor(\n",
    "        hidden_layer_sizes=(16, 8),  # Example architecture\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=2000,\n",
    "        random_state=42\n",
    "    )\n",
    "    nn_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 7. Evaluate on the test set\n",
    "    y_pred = nn_model.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adjusted R² = 1 - (1 - R²)*(n - 1)/(n - p - 1)\n",
    "    n = len(y_test)\n",
    "    p = X_test_scaled.shape[1]\n",
    "    if n > p + 1:\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    else:\n",
    "        adjusted_r2 = float('nan')\n",
    "    \n",
    "    print(\"\\n=== Neural Network Model (Test Set) ===\")\n",
    "    print(\"Architecture: hidden_layer_sizes=(16, 8), activation='relu'\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    \n",
    "    # 8. Interactive input for new SMILES outside the dataset\n",
    "    print(\"\\n=== Predict Enhancement Factor for a new SMILES ===\")\n",
    "    while True:\n",
    "        user_input = input(\"Enter a SMILES string (or type 'quit' to exit): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "        \n",
    "        new_fp = smiles_to_morgan_fp(user_input, radius=2, n_bits=1024)\n",
    "        if new_fp is None:\n",
    "            print(\"Invalid SMILES entered. Please try again.\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Scale the new fingerprint\n",
    "        new_fp_scaled = scaler.transform([new_fp])\n",
    "        pred_val = nn_model.predict(new_fp_scaled)[0]\n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e71f62",
   "metadata": {},
   "source": [
    "Above is the test model for NN. Below represents a fine tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a403d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                         Name  \\\n",
      "0     1         Ibuprofen / HP-B-CD   \n",
      "1     2      Dexamethasone / B - CD   \n",
      "2     3         Piroxicam / HP-B-CD   \n",
      "3     4    Hydrocortisone / HP-B-CD   \n",
      "4     5       Albendazole / RM-B-CD   \n",
      "5     6            Valtarsan / B-CD   \n",
      "6     7        Nifedipine / HP-B-CD   \n",
      "7     8        Nimodipine / HP-B-CD   \n",
      "8     9     Carbamazepine / HP-B-CD   \n",
      "9    10      Itraconazole / HP-B-CD   \n",
      "10   11       Simvastatin / HP-B-CD   \n",
      "11   12          Curcumin / HP-B-CD   \n",
      "12   13  Indomethacin / HP- B - CD    \n",
      "13   14     Naproxen / HP - B - CD    \n",
      "14   15        Diclofenac / HP-B-CD   \n",
      "15   16   Resveratrol / HP-Gamma CD   \n",
      "16   17              Amphotericin B   \n",
      "17   18                 Budesonide    \n",
      "\n",
      "                                               Smiles MolWeight  LogP  \\\n",
      "0                          CC(C)Cc1ccc(cc1)C(C)C(=O)O   1606.29  3.84   \n",
      "1   CC(C)C1C(=O)CC2C(C1O)(CC(C1=CC(=O)C=C2C1(C)O)F...   1527.47  1.93   \n",
      "2                     CN1NS(=O)(=O)C2=C(O)C=CN=C2C1=O   1466.35   2.2   \n",
      "3              CC(=O)C1(CCC2C1(CCC1C(C2CC(C1O)O)O)C)O   1762.46  1.79   \n",
      "4                      CCCSC1=CC=C2C=C1N=C(C(=O)OC)N2   250.323  3.22   \n",
      "5   CC(C)C[C@H](C(=O)NCc1ccc(cc1)c1ccccc1C(=N)N=N)...    1570.5  3.68   \n",
      "6   CCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])C)...      1846  2.49   \n",
      "7   COCCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])...    418.44  3.41   \n",
      "8                        O=C1Nc2ccccc2C2=CC=CC=C2C1=O  1371.25    2.1   \n",
      "9   CC1=NC(C)=NC(OCC2CCC(OC3=NC(N4CCN(C)CC4)=NC(C4...    1840.6  5.48   \n",
      "10  CC(C)CC(CC=C)C(=O)OC[C@@H]1CC[C@@H](CC1)C(=O)O...   1553.55  4.51   \n",
      "11      COc1ccc(cc1)/C=C/C(=O)CC(=O)/C=C/c1ccc(cc1)OC   1503.36  3.62   \n",
      "12      COc1ccc2c(c1)n(c(c2C(=O)O)C(=O)c1ccc(cc1)Cl)C    1492.8  4.46   \n",
      "13                       COc1cc2ccc(C(C)C(=O)O)cc2cc1   1365.24  3.39   \n",
      "14                   OC(=O)Cc1cccc(c1)Nc1c(cccc1Cl)Cl   1431.15  4.75   \n",
      "15               OC1=CC=CC(/C=C/C2=CC(O)=CC(O)=C2)=C1  1728.247  2.57   \n",
      "16  CC(C)CCCC(C)CCCC(C)C(C)CCC/C=C\\C/C=C\\C/C=C\\C/C...         -     -   \n",
      "17  CC(=CC(=O)C12CCC(C)CC1CCC1C2CCC2OC(C)(C)CC1(C)...         -     -   \n",
      "\n",
      "       LogS (CD)  HPCalculated  Descriptors   \\\n",
      "0           -3.5           NaN           NaN   \n",
      "1    2.979852707           NaN           NaN   \n",
      "2    4.166237644           NaN           NaN   \n",
      "3    1.831145921           NaN           NaN   \n",
      "4      0.9213795           NaN           NaN   \n",
      "5    2.920818754           NaN           NaN   \n",
      "6    3.915983678           NaN           NaN   \n",
      "7    3.881270504           NaN           NaN   \n",
      "8   -2.331615782           NaN           NaN   \n",
      "9    4.833595654           NaN           NaN   \n",
      "10    3.93605273           NaN           NaN   \n",
      "11    4.08504452           NaN           NaN   \n",
      "12   4.229518954           NaN           NaN   \n",
      "13   1.754487332           NaN           NaN   \n",
      "14   4.803502637           NaN           NaN   \n",
      "15   3.196213127           NaN           NaN   \n",
      "16             -           NaN           NaN   \n",
      "17             -           NaN           NaN   \n",
      "\n",
      "    CD-complex solubility (mg/ml; unless stated otherwise)  \\\n",
      "0                                                 NaN        \n",
      "1                                            1.600000        \n",
      "2                                            0.100000        \n",
      "3                                           26.000000        \n",
      "4                                           30.000000        \n",
      "5                                            1.884600        \n",
      "6                                            0.224000        \n",
      "7                                            0.055000        \n",
      "8                                            6.390000        \n",
      "9                                            0.027000        \n",
      "10                                           0.180000        \n",
      "11                                           0.123600        \n",
      "12                                           0.088000        \n",
      "13                                          24.028224        \n",
      "14                                           0.022500        \n",
      "15                                           1.100000        \n",
      "16                                           0.150000        \n",
      "17                                           0.845000        \n",
      "\n",
      "    Intrinistic solubility (mg/ml; unless stated otherwise  Enhancement Factor  \n",
      "0                                                 NaN                30.000000  \n",
      "1                                            0.160000                10.000000  \n",
      "2                                            0.023000                 4.347826  \n",
      "3                                            0.280000                71.400000  \n",
      "4                                            0.010000               600.000000  \n",
      "5                                            0.003192               590.783000  \n",
      "6                                            0.005000                44.800000  \n",
      "7                                            0.002500                22.000000  \n",
      "8                                            0.140000                45.600000  \n",
      "9                                            0.000001             27000.000000  \n",
      "10                                           0.030000                 6.000000  \n",
      "11                                           0.000600               206.000000  \n",
      "12                                           0.008800                10.000000  \n",
      "13                                           0.115131               208.704900  \n",
      "14                                           0.003000                 7.500000  \n",
      "15                                           0.030000                36.666667  \n",
      "16                                           0.001000               150.000000  \n",
      "17                                           0.022000                38.409091  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n",
      "[01:36:54] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Neural Network Model (Test Set) ===\n",
      "Log-transform of Enhancement Factor + 256-bit fingerprints\n",
      "Architecture: hidden_layer_sizes=(16, 8), activation='relu'\n",
      "MSE  : 147778.6841\n",
      "RMSE : 384.4199\n",
      "MAE  : 159.6996\n",
      "R²   : -0.2065\n",
      "Adjusted R²: nan\n",
      "\n",
      "=== Predict Enhancement Factor for a new SMILES ===\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RDKit for SMILES parsing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# For train-test split, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# For feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Simple neural network regressor from scikit-learn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=2, n_bits=256):\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to a Morgan fingerprint (ECFP) vector of length n_bits.\n",
    "    Returns a NumPy array of shape (n_bits,) or None if SMILES is invalid.\n",
    "\n",
    "    Reduced from 1024 to 256 bits to help avoid overfitting on a small dataset.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def main():\n",
    "    # 1. Load your CSV dataset (adjust filename/column names as needed)\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head(18))  # Quick look at data\n",
    "    \n",
    "    # 2. Basic cleaning\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    \n",
    "    # Drop rows with missing values in 'Smiles' or 'Enhancement Factor'\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    # 3. Convert SMILES to numeric features (256-bit Morgan fingerprints)\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    enhancement_factors = df[\"Enhancement Factor\"].values\n",
    "    \n",
    "    X_fps = []\n",
    "    valid_y = []\n",
    "    for smi, val in zip(smiles_list, enhancement_factors):\n",
    "        fp = smiles_to_morgan_fp(smi, radius=2, n_bits=256)\n",
    "        if fp is not None:\n",
    "            X_fps.append(fp)\n",
    "            valid_y.append(val)\n",
    "    \n",
    "    X = np.array(X_fps, dtype=float)\n",
    "    y = np.array(valid_y, dtype=float)\n",
    "    \n",
    "    # --- NEW: Log-transform the Enhancement Factor ---\n",
    "    # If EF is always > 0, np.log1p can drastically reduce MSE.\n",
    "    y_log = np.log1p(y)  # log(1 + EF)\n",
    "    \n",
    "    # 4. Train-test split\n",
    "    X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
    "        X, y_log, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # 5. Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    \n",
    "    # 6. Define and train a neural network (MLPRegressor)\n",
    "    nn_model = MLPRegressor(\n",
    "        hidden_layer_sizes=(16, 8),  # Example architecture\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=2000,\n",
    "        random_state=42\n",
    "    )\n",
    "    nn_model.fit(X_train_scaled, y_train_log)\n",
    "    \n",
    "    # 7. Evaluate on the test set\n",
    "    #    Predictions are in log space, so exponentiate back\n",
    "    y_pred_log = nn_model.predict(X_test_scaled)\n",
    "    y_pred = np.expm1(y_pred_log)  # revert from log(EF) to EF\n",
    "    \n",
    "    # Convert y_test_log back to original EF scale\n",
    "    y_test = np.expm1(y_test_log)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adjusted R²\n",
    "    n = len(y_test)\n",
    "    p = X_test_scaled.shape[1]\n",
    "    if n > p + 1:\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    else:\n",
    "        adjusted_r2 = float('nan')\n",
    "    \n",
    "    print(\"\\n=== Neural Network Model (Test Set) ===\")\n",
    "    print(\"Log-transform of Enhancement Factor + 256-bit fingerprints\")\n",
    "    print(\"Architecture: hidden_layer_sizes=(16, 8), activation='relu'\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    \n",
    "    # 8. Interactive input for new SMILES outside the dataset\n",
    "    print(\"\\n=== Predict Enhancement Factor for a new SMILES ===\")\n",
    "    while True:\n",
    "        user_input = input(\"Enter a SMILES string (or type 'quit' to exit): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "        \n",
    "        new_fp = smiles_to_morgan_fp(user_input, radius=2, n_bits=256)\n",
    "        if new_fp is None:\n",
    "            print(\"Invalid SMILES entered. Please try again.\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Scale the new fingerprint\n",
    "        new_fp_scaled = scaler.transform([new_fp])\n",
    "        # Predict in log space, then exponentiate\n",
    "        pred_log = nn_model.predict(new_fp_scaled)[0]\n",
    "        pred_val = np.expm1(pred_log)\n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac99a5f",
   "metadata": {},
   "source": [
    "Below is a siginifacnly improved model\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8eb6f38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23604\\644085544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# RDKit for molecular descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Lipinski, MACCSkeys\n",
    "\n",
    "# Train-test split, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=3, n_bits=2048):\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to a Morgan fingerprint with higher bit count\n",
    "    for better representation of structural features\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def smiles_to_maccs(smi):\n",
    "    \"\"\"\n",
    "    Convert SMILES to MACCS keys (166-bit fingerprint)\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    arr = np.zeros((167,), dtype=int)  # MACCS has 167 bits\n",
    "    for i in range(167):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def calculate_molecular_descriptors(smi):\n",
    "    \"\"\"\n",
    "    Calculate additional molecular descriptors to capture physicochemical properties\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    descriptors = []\n",
    "    \n",
    "    # Basic properties\n",
    "    descriptors.append(Descriptors.MolWt(mol))                 # Molecular weight\n",
    "    descriptors.append(Descriptors.MolLogP(mol))               # LogP\n",
    "    descriptors.append(Descriptors.TPSA(mol))                  # Topological polar surface area\n",
    "    descriptors.append(Descriptors.NumHDonors(mol))            # Number of H-bond donors\n",
    "    descriptors.append(Descriptors.NumHAcceptors(mol))         # Number of H-bond acceptors\n",
    "    descriptors.append(Descriptors.NumRotatableBonds(mol))     # Number of rotatable bonds\n",
    "    descriptors.append(Descriptors.NumAromaticRings(mol))      # Number of aromatic rings\n",
    "    descriptors.append(Descriptors.NumAliphaticRings(mol))     # Number of aliphatic rings\n",
    "    descriptors.append(Descriptors.NumSaturatedRings(mol))     # Number of saturated rings\n",
    "    descriptors.append(Descriptors.FractionCSP3(mol))          # Fraction of C atoms that are sp3 hybridized\n",
    "    descriptors.append(Descriptors.NumHeteroatoms(mol))        # Number of heteroatoms\n",
    "    descriptors.append(Descriptors.HeavyAtomCount(mol))        # Number of heavy atoms\n",
    "    descriptors.append(Descriptors.NumValenceElectrons(mol))   # Number of valence electrons\n",
    "    descriptors.append(Descriptors.BalabanJ(mol))              # Balaban's J value\n",
    "    descriptors.append(Descriptors.BertzCT(mol))               # Bertz CT\n",
    "    \n",
    "    # Additional descriptors\n",
    "    descriptors.append(Descriptors.Chi0n(mol))                 # Connectivity index\n",
    "    descriptors.append(Descriptors.Chi0v(mol))                 # Valence connectivity index\n",
    "    descriptors.append(Descriptors.HallKierAlpha(mol))         # Hall-Kier alpha value\n",
    "    descriptors.append(Descriptors.Kappa1(mol))                # Kappa shape index\n",
    "    descriptors.append(Descriptors.LabuteASA(mol))             # Labute ASA\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "def create_nn_model(input_dim, dropout_rate=0.3, l1_reg=0.001, l2_reg=0.001):\n",
    "    \"\"\"\n",
    "    Create a neural network model with regularization to prevent overfitting\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,), \n",
    "              kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(1)  # Output layer (no activation for regression)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_ensemble_model(input_dim):\n",
    "    \"\"\"\n",
    "    Create an ensemble of sub-models with different architectures\n",
    "    \"\"\"\n",
    "    # Base model inputs\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    \n",
    "    # Sub-model 1: Deep network with more regularization\n",
    "    x1 = Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "    x1 = Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "    x1 = Dense(32, activation='relu')(x1)\n",
    "    x1 = Dense(1, name='model1_output')(x1)\n",
    "    \n",
    "    # Sub-model 2: Shallower network with less regularization\n",
    "    x2 = Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.0005, l2=0.0005))(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    x2 = Dense(32, activation='relu')(x2)\n",
    "    x2 = Dense(1, name='model2_output')(x2)\n",
    "    \n",
    "    # Sub-model 3: Very shallow network\n",
    "    x3 = Dense(32, activation='relu')(inputs)\n",
    "    x3 = Dense(16, activation='relu')(x3)\n",
    "    x3 = Dense(1, name='model3_output')(x3)\n",
    "    \n",
    "    # Combine predictions (average)\n",
    "    outputs = tf.keras.layers.Average()([x1, x2, x3])\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def visualize_predictions(y_true, y_pred, title):\n",
    "    \"\"\"\n",
    "    Create a visualization of predictions vs actual values\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a scatter plot\n",
    "    plt.scatter(y_true, y_pred, alpha=0.7)\n",
    "    \n",
    "    # Add a perfect prediction line\n",
    "    max_val = max(np.max(y_true), np.max(y_pred))\n",
    "    min_val = min(np.min(y_true), np.min(y_pred))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    # Calculate and display R² value\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    plt.text(0.05, 0.95, f'R² = {r2:.4f}', transform=plt.gca().transAxes, \n",
    "             fontsize=12, verticalalignment='top')\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel('Actual Enhancement Factor')\n",
    "    plt.ylabel('Predicted Enhancement Factor')\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title.replace(' ', '_')}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Data cleaning\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "    print(f\"Enhancement Factor range: {df['Enhancement Factor'].min()} to {df['Enhancement Factor'].max()}\")\n",
    "    \n",
    "    # Extract SMILES and target values\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    enhancement_factors = df[\"Enhancement Factor\"].values\n",
    "    \n",
    "    # Log-transform target due to wide range\n",
    "    enhancement_factors_log = np.log1p(enhancement_factors)\n",
    "    \n",
    "    # Feature extraction\n",
    "    print(\"Extracting molecular features...\")\n",
    "    features_list = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i, smi in enumerate(smiles_list):\n",
    "        # Get Morgan fingerprint (2048 bits, radius 3)\n",
    "        morgan_fp = smiles_to_morgan_fp(smi, radius=3, n_bits=2048)\n",
    "        \n",
    "        # Get MACCS keys fingerprint (167 bits)\n",
    "        maccs_fp = smiles_to_maccs(smi)\n",
    "        \n",
    "        # Get descriptors\n",
    "        descriptors = calculate_molecular_descriptors(smi)\n",
    "        \n",
    "        if morgan_fp is not None and maccs_fp is not None and descriptors is not None:\n",
    "            # Combine all features\n",
    "            combined_features = np.concatenate([morgan_fp, maccs_fp, descriptors])\n",
    "            features_list.append(combined_features)\n",
    "            valid_indices.append(i)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(features_list)\n",
    "    y = enhancement_factors_log[valid_indices]  # Using log-transformed target\n",
    "    y_original = enhancement_factors[valid_indices]  # Original values for evaluation\n",
    "    \n",
    "    print(f\"Features extracted. X shape: {X.shape}\")\n",
    "    \n",
    "    # Remove near-zero variance features\n",
    "    variance = np.var(X, axis=0)\n",
    "    keep_indices = np.where(variance > 0.01)[0]\n",
    "    X = X[:, keep_indices]\n",
    "    print(f\"After removing low-variance features: {X.shape}\")\n",
    "    \n",
    "    # Feature selection with Random Forest\n",
    "    print(\"Performing feature selection...\")\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Select features based on importance\n",
    "    selector = SelectFromModel(rf, threshold=\"mean\", prefit=True)\n",
    "    X_selected = selector.transform(X)\n",
    "    print(f\"After feature selection: {X_selected.shape}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "    \n",
    "    # Bin the target for stratified sampling\n",
    "    y_bins = pd.qcut(y, q=5, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Split data with stratification\n",
    "    X_train, X_test, y_train, y_test, y_orig_train, y_orig_test = train_test_split(\n",
    "        X_scaled, y, y_original, test_size=0.2, random_state=42, stratify=y_bins\n",
    "    )\n",
    "    \n",
    "    print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "    \n",
    "    # K-fold cross-validation to ensure robustness\n",
    "    print(\"Performing cross-validation...\")\n",
    "    k_fold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(k_fold.split(X_train)):\n",
    "        print(f\"\\nFold {fold+1}/5\")\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Create and train ensemble model\n",
    "        model = create_ensemble_model(X_fold_train.shape[1])\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=30,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            epochs=200,\n",
    "            batch_size=8,  # Small batch size for small dataset\n",
    "            validation_data=(X_fold_val, y_fold_val),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_fold_pred = model.predict(X_fold_val).flatten()\n",
    "        fold_r2 = r2_score(y_fold_val, y_fold_pred)\n",
    "        cv_scores.append(fold_r2)\n",
    "        print(f\"Fold {fold+1} R²: {fold_r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nCross-validation R² scores: {cv_scores}\")\n",
    "    print(f\"Mean CV R²: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "    \n",
    "    # Train final model on all training data\n",
    "    print(\"\\nTraining final model...\")\n",
    "    final_model = create_ensemble_model(X_train.shape[1])\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=50,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=15,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train with validation split for early stopping\n",
    "    history = final_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=300,\n",
    "        batch_size=8,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_log = final_model.predict(X_test).flatten()\n",
    "    \n",
    "    # Convert predictions back to original scale\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    \n",
    "    # Calculate metrics on log scale\n",
    "    mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "    rmse_log = np.sqrt(mse_log)\n",
    "    mae_log = mean_absolute_error(y_test, y_pred_log)\n",
    "    r2_log = r2_score(y_test, y_pred_log)\n",
    "    \n",
    "    # Calculate metrics on original scale\n",
    "    mse = mean_squared_error(y_orig_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_orig_test, y_pred)\n",
    "    r2 = r2_score(y_orig_test, y_pred)\n",
    "    \n",
    "    # Calculate adjusted R²\n",
    "    n = len(y_test)\n",
    "    p = X_test.shape[1]\n",
    "    if n > p + 1:\n",
    "        adjusted_r2_log = 1 - (1 - r2_log) * (n - 1) / (n - p - 1)\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    else:\n",
    "        adjusted_r2_log = adjusted_r2 = float('nan')\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Neural Network Ensemble Results (Test Set) ===\")\n",
    "    print(\"Log-transformed space:\")\n",
    "    print(f\"MSE  : {mse_log:.4f}\")\n",
    "    print(f\"RMSE : {rmse_log:.4f}\")\n",
    "    print(f\"MAE  : {mae_log:.4f}\")\n",
    "    print(f\"R²   : {r2_log:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2_log:.4f}\")\n",
    "    \n",
    "    print(\"\\nOriginal space:\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    visualize_predictions(y_orig_test, y_pred, \"Neural Network: Actual vs Predicted\")\n",
    "    \n",
    "    # Save final model for future use\n",
    "    final_model.save('enhancement_factor_model.h5')\n",
    "    \n",
    "    # Save feature processing pipeline\n",
    "    import pickle\n",
    "    with open('model_preprocessing.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'scaler': scaler,\n",
    "            'feature_selector': selector,\n",
    "            'keep_indices': keep_indices\n",
    "        }, f)\n",
    "    \n",
    "    # Interactive prediction loop\n",
    "    print(\"\\n=== Predict Enhancement Factor for new SMILES ===\")\n",
    "    while True:\n",
    "        user_input = input(\"Enter a SMILES string (or 'quit' to exit): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "        \n",
    "        # Extract features\n",
    "        morgan_fp = smiles_to_morgan_fp(user_input, radius=3, n_bits=2048)\n",
    "        maccs_fp = smiles_to_maccs(user_input)\n",
    "        descriptors = calculate_molecular_descriptors(user_input)\n",
    "        \n",
    "        if morgan_fp is None or maccs_fp is None or descriptors is None:\n",
    "            print(\"Invalid SMILES entered. Please try again.\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate([morgan_fp, maccs_fp, descriptors])\n",
    "        \n",
    "        # Apply same preprocessing steps\n",
    "        features = combined_features[keep_indices]  # Apply variance filter\n",
    "        features = selector.transform([features])  # Apply feature selection\n",
    "        features_scaled = scaler.transform(features)  # Apply scaling\n",
    "        \n",
    "        # Predict\n",
    "        pred_log = final_model.predict(features_scaled).flatten()[0]\n",
    "        pred_val = np.expm1(pred_log)\n",
    "        \n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243ab99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
