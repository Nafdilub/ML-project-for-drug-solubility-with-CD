{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283236fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2024.9.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from rdkit) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from rdkit) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gagno\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\gagno\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: xgboost in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\gagno\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: dask in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2024.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (2022.7.1)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (2.0.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (21.3)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (0.11.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (8.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from dask) (8.1.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from click>=8.1->dask) (0.4.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.13.0->dask) (3.21.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask) (3.0.9)\n",
      "Requirement already satisfied: locket in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\gagno\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install joblib\n",
    "!pip install --upgrade pandas dask\n",
    "!pip install --upgrade lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442248fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAASfElEQVR4nO3deVBTV/8G8ENAFmVzAwF3B/e2YqzV4jij6LRailXLJgSkQNQqQetI/tCp02odxqICKp1EVIJsiUsrFbUD4tSidgHFFXFBigiC7ChrlveP219efr7WhZtwkpvn86eDN8+E8fF8c3PPMdNoNAQAAHqLRzsAAIBxQ40CALCCGgUAYAU1CgDACmoUAIAV1CgAACuoUQAAVlCjAACsoEYBAFhBjQIAsIIaBQBgBTUKAMAKahQAgBXUKAAAK6hRAABWUKMAAKygRgEAWEGNAgCwghoFAGAFNQoAwApqFACAFdQoAAArqFEAAFZQowAArKBGAQBYQY0CALCCGjUVGo2GdgQAbkKNcpxGo9m9e7erq6uFhYWzs3NxcTHtRABcgxrlrOrqaj8/P2tr640bN1ZXV6vV6traWj6fHxcXRzsaAKegRjkoNzd3xowZbm5uR48e7erqMjc39/Lyys7OHjx4sFqt3rRp05w5c7q6umjHBOAIM3xkxhlqtTo/Pz8hIeHUqVPMn/Tv3z84OHjPnj39+/dnfsDb2/vMmTOEEEdHx/Pnz0+bNo1mYgBOwGqUC1paWqRS6dSpUxcuXHjq1ClLS0t3d3eFQvH8+XOJRMJ0KCGEx+OdPn16165dPB6vqamJz+cnJyfTTQ7AAViNGre7d+/u37//0KFDz549I4S4ublFRERERUUNHjz4FX/r9u3bc+fOra+vNzMzi4mJ+e6778zNzfsqMgDXoEaNknZ+z8nJYX6Dnp6e0dHRS5cutbCweJMrKJXKb7/9dseOHSqVat68eenp6S4uLnpODcBNqFEj09zcnJKSEh8fX15eTgixtbVdsWJFVFTU1KlTe3G18+fPBwUFVVdXOzk5paWlLVy4UMdxAUwAatRoFBcX//DDD2lpaW1tbYSQcePGRUZGRkZGDho0iM1la2trg4ODc3Nzzc3Nt2zZ8vXXX/N4+MQc4C2gRg2dSqU6ffp0YmJiXl4eIYTH482fP18oFC5btkxXH2iqVKpt27Zt27ZNrVbPmzcvIyNj2LBhOrkygClAjRqu2traw4cPJyUlVVRUEELs7e0DAgKio6MnT56sj5fLz88PCgp68uSJk5NTenr6ggUL9PEqANyDGjVERUVFUqn0yJEj7e3thJDx48d/+eWX4eHhtra2en3dmpqa4ODgvLw8DPgAbw41akC6urpOnjwplUp7zu8ikcjb29vMzKxvMvQc8OfPn5+eno4BH+DVUKMG4cmTJzKZbN++fZWVlYQQBweH0NDQ9evXjxkzhkqec+fOBQUF1dTUuLm5ZWVlzZkzh0oMAKOAGqWsqKgoISEhKyuru7ubEDJx4sTVq1dHREQMGDCAbrDKysrAwMCCggILC4vNmzdjwAf4N6hROjo7O7Ozs/fs2XP58mVCCI/HW7x4cXR0tJeXV5/N76+lVCq3b9/ODPheXl7p6enOzs60QwEYHNRoX6uurpZIJElJSU+fPiWEODk5hYWFrVmzZtSoUbSjvVxeXl5wcHBNTc3w4cMzMzMx4AO8ADXad5j5PTMzU6lUEkKmT5++atUqgUBgY2NDO9prVFZWBgQEXLx4EQM+wP9CjepdR0eHQqHYtWvX9evXCSGWlpZLliwRCoXG9cXMngO+t7d3SkrKq3c/ATAdqFE9Kisrk0qlycnJ9fX1hBBnZ+eVK1euW7du+PDhtKP10qlTp0JDQxsaGkaMGJGZmenp6Uk7EQB9qFG9KCgoSExMPHHihEqlIoTw+XyhUBgSEmJtbU07GluPHj0KDAzEgA+ghRrVpdbW1szMzL179968eZMQYmVl5ePjs379+g8//JB2NF3qOeB/+umnKSkpLLdHATBqqFHduH//fnJyslQqbWxsJIS4uLgIhcK1a9cOHTqUdjR9+fnnn1euXMkM+FlZWRz7rwLgzaFGWWG2T5ZKpT3nd5FIFBgY2K9fP9rp9O7Ro0cBAQGXLl2ysLDYvn17TEyM4XzpFaDPoEZ7qaWlJSsrKz4+vqSkhBBiZWXl5+e3cePG9957j3a0PqVUKrds2bJz506NRuPj43P48GEM+GBqUKNvrXfHH3FbdnZ2WFhYQ0PDyJEjs7KyZs+eTTsRQN9Bjb4p9scfcVtFRUVAQMDly5cx4IOpQY2+nm6PP+KwngP+kiVLDh8+PHDgQNqhAPQONfoqejr+iNtOnjwZFhbW2Ng4cuRIuVw+a9Ys2okA9As1+hJqtTonJ0evxx9xW0VFhb+//++//96vX79t27ZhwAduQ43+P318/BGHdXZ2xsTEJCYmEkI+++yzQ4cOYcAHrkKN/uOF44/c3d3Dw8NXrVrl6OhIO5oR++mnn7744ovGxsZRo0bJ5fIPPviAdiIAPdCYts7OToVCod1sicfjLViwIDs7W61W047GEeXl5Ux7WllZxcfH044D8I/CwsLQ0NC8vDz2lzLdGq2uro6NjdVutuTg4CASicrKymjn4qCOjg6RSMS8z0uXLm1sbKSdCExXZ2dnRkaG9qvNPj4+7K9pijVaWFgoEAi0D2tOnDgxPj7+2bNntHNx3IkTJ5hPSEaPHv3HH3/QjgMm58mTJ7GxsSNGjGD+4dvb2wuFwpKSEvZXNqEaZbZP1v4vxOPxvL29c3NzMb/3mYcPH86cORMDPvSxwsJCoVCo3aZywoQJul05mUSNVlVVbd26VbvZ0tChQ8VicXl5Oe1cpqjngL9s2TIM+KA/zJ0P7d5j+ls5cbxGmfld+7Dm9OnTJRJJW1sb7Vym7vjx48yA7+7ufvXqVdpxgGteWDk5OjqKRCL9rZy4WaPt7e0ymezdd99l3kRLS0tfX9/c3FzaueC/SktLmd2wrK2tMeCDrrxw58PDw0MikTx//lyvL8q1Gn3w4IFYLNZutuTs7CwWiysqKmjngpdob2/XDvjLly9vamqinQiMVUdHh0wm025TaW5uzszvffPq3KnR3377zdfXVzu/8/l8iUTS3t5OOxe8xrFjxxwcHAgh48ePLy4uph0HjMzjx4+3bt06ZMgQ5h++k5NT36+cjL5GW1paJBKJdrMlZn6/ePEi7VzwFkpLS5lPYDDgw5t76cqJyp0PI67Re/fuicVi7ZPaLi4uW7dura2tpZ0LeqPngB8cHNza2ko7ERio1tZWiUTyzjvv9Fw5FRQUUIxkfDWqUqlyc3N9fX21my3x+XyZTNbV1UU7GrB15MgRW1tb5pt9165dox0HDMv9+/fFYrF2m8phw4aJxeLKykrauYyqRpubmyUSyaRJk5g30crKSiAQ4NM0jrlz5w4GfOhJrVYb+MrJOGq0tLRUJBIx6xRCiKur69atW+vq6mjnAr3oOeALBAI8p2uymDsf2m0qraysfH19L1++TDvXiwy6Rpn53dvbW7vpr6enp0Kh6O7uph0N9C41NXXAgAHMpgfXr1+nHQf61N27d8VisXabSmbl9PTpU9q5Xs5Aa7SpqSk+Pn706NHMm2hraysUCm/cuEE7F/SpkpIS5k6CjY2NVCqlHQf0zkhXTgZXo1evXhUKhf3792fexHHjxsXGxtbX19POBXS0tbVFRkZiwOc8ZuU0ZswY5ndtbW0tEAiMZQoxlBpVqVTZ2dkvbJ+sUCiUSiXtaECfTCbTDvgYSjjmzp07IpGI+f0a6cqJfo3W1NTExsaOHDmSeRPt7OyEQuGtW7do5wLDUlJSwjxkYWNjc+DAAdpxgC3tyomZ383MzIx35USzRplNAG1sbJgCdXd3j42Nxc5p8G/a2toiIiIw4Bu7xsbG+Pj4UaNG9Vw53bx5k3au3qNQozj+CNiQyWTMR+eTJk3CgG9cioqKet75YFZODQ0NtHOx1ac1iuOPQCdu3749ZcoU5iscaWlptOPAa3B+5dRHNYrjj0C3Wltbg4KCtAO+vjeUhN7R3/FHBkW/NYrjj0CvtAP+5MmTjfrDNe7R9/FHBkVfNdrHm/iDybp16xbzsKCdnV16ejrtOKauz44/Mii6r1EcfwR9rKWlJTAwEAM+XVVVVbGxsW5ubia4ctJZjeL4I6BLO+BPmzbt7t27tOOYECrHHxkUHdQojj8CA3HlyhV3d3dmwM/IyKAdh+PoHn9kUHRQoz4+Psz7OHv27IyMjM7OTvbXBOidlpaWgIAA7YCPT5P0wRCOPzIoOqjRvLy80NDQwsJC9pcC0AmZTMY8Hefh4XHv3j3acbjDcI4/MihmGo2GAHDO1atX/fz87t+/b2dnJ5VKtUtU6IVnz55lZGTs27fvxo0bhBBLS8slS5ZER0d7enrSjmYQUKPAWa2trZGRkXK5nBAiEAgkEol2Awd4Qw8ePDhw4MCBAwcaGhoIIcOGDQsNDY2KitLekQeCGgXOk0qlIpGos7Nz+vTpCoVi3LhxtBMZAY1Gc+7cOalUeuLECZVKRQjh8/kikSgwMFB7Rx60UKPAfVeuXPHz83vw4IG9vb1UKvX396edyHC1trZmZmYmJCTcvn2bEGJlZeXj4/PVV1/NmjWLdjTDhRoFk9DS0hIZGalQKAghQqFw7969lpaWtEMZlnv37h08eFAikTQ1NRFCXF1dIyMj161bp70jD/8GNQomRCqVRkVFdXV18fl8uVyOAZ8Qolar8/PzExIScnJymDbw9PSMjo5eunSp9o48vBpqFExLUVGRv78/M+AnJyf7+vrSTkRNc3NzSkpKQkLCw4cPCSHW1ta+vr6bNm1ijhGEN4caBZPT0tISERFx9OhRYqoDfmlpaVJS0sGDB58/f04IGTt2rFAojIyMHDRoEO1oRgk1CiZKO+DPmDFDLpePHTuWdiK9U6vVOTk5iYmJ586d02g0ZmZmXl5eQqFw2bJl5ubmtNMZMdQomK7CwkJ/f/+ysjIHB4fk5OTPP/+cdiJ9aWpqkslke/bs+fvvvwkhdnZ2gYGBIpGIOUQAWEKNgklrbm6OiIg4duyYmZlZVFTU999/z7EB/8qVKxKJJC0tra2tjRDi7u4eHh4uFAoHDhxIOxp3oEbB1Gk0msTExJiYGGbAVygUY8aMoR2Kra6urpMnT0ql0ry8PEIIj8ebP3++SCTy9vZmDjQGHUKNAhBCyF9//eXv7//w4UMHB4eDBw8uX76cdqJeqqmpSUlJ2b9//6NHjwgh9vb2AQEBGzZsmDhxIu1onIUaBfhHc3NzeHj48ePHjXTALyoqkkqlqampHR0dhJAJEyasWbMmIiJiwIABtKNxHGoU4L+YAX/Tpk3d3d3vv/++XC43/AGfmd/j4+MvXbpECOHxeIsXL46Ojvby8sL83jdQowAv0g74gwcPlslkn3zyCe1EL1ddXZ2amrp3797Hjx8TQhwdHUNCQjZs2DB69Gja0UwLahTgJerr60NCQk6fPs0M+HFxcQa1s1FRUVFCQkJWVlZ3dzchxMPDY/Xq1cHBwcxpVNDHUKMAL9dzwJ85c6ZcLqe+yuvs7JTL5bt377527RohxNzcfNGiRdHR0QsWLKAbzMShRgFe5c8///T39y8vLx8yZIhMJlu8eDGVGFVVVVKpdP/+/XV1dYQQJyensLCwtWvXjhgxgkoe6Ak1CvAadXV1ISEhZ86coTLgFxQUJCYm/vjjj0qlkhDC5/OFQqFAIMBO/oYDNQrwej0H/Llz52ZkZOj7FI2Ojg6FQhEXF4fjjwwfahTgTV24cGHFihWPHz8eMmRIamrqokWL9PEqOP7I6KBGAd5CXV2dQCA4e/aszgd8HH9kvFCjAG/nhQE/MzPT1dWVzQVx/JGxQ40C9MaFCxcCAwOrqqqGDh2ampr68ccf9+IiOP6IG1CjAL309OlTgUDwyy+/vO0z+Dj+iGNQowC9p9Fodu7cuXnzZpVK5ejomJ+f7+Hh8Yqfx/FHnIQaBWArNTU1LCxMrVbzeLwdO3aIxeL//Zns7OzNmzeXlZUx2yfj+CMuQY0C6MCdO3fmzJlTX19PCJk1a9avv/7KDPhKpfKbb75JSkpivr1E/m9+x/FHXIIaBdANpVK5aNEiZrf5gQMHpqamSiSSs2fPMk8fmZmZTZkyJTY21mD3i4JeQ40C6FJcXJxYLFar1do/YR5ASkhIcHFxoRgM9Ac1CqBjxcXFH330UV1d3aBBg6KiorZs2cLj8WiHAj1CjQLoBXMQPO0U0BdQowAArGDWAABgBTUKAMAKahQAgBXUKAAAK6hRAABWUKMAAKygRgEAWEGNAgCwghoFAGAFNQoAwApqFACAFdQoAAArqFEAAFZQowAArKBGAQBYQY0CALCCGgUAYAU1CgDACmoUAIAV1CgAACuoUQAAVlCjAACsoEYBAFhBjQIAsIIaBQBgBTUKAMDKfwCJ9xgB6RmMygAAAHl6VFh0cmRraXRQS0wgcmRraXQgMjAyNC4wOS41AAB4nHu/b+09BiAQAGImBghgAWJmIG5gZGNIANKMzBCaiQmVZmTmZmBkYGRiYGJmcAJpFLcCiTLAjPmW/Hd/5zHufSDOgwLJ/dcvPbODsu2BbLA4UI09UA1YXAwA/CcZgWMGxLIAAAC/elRYdE1PTCByZGtpdCAyMDI0LjA5LjUAAHicfZDdDoIwDIXv9xTnBVi6H8BeMkaMMYxE0Xfw3vePnQYGiaHdknb7ztpOIdstXl9vrGajUgAdLGbG0xGRGpEDhOF8SejnLiwn/fRI8x0eThTie7Kbp3E5MehRGc0tN8ahIm1cU5NINH2taG0mSdfMrmW59zWdbPsHdAKuXHUAegHX0geVhxR3Pf+mCFOKZYrstrQqCVxpyMj22+e24pwvnyex+gDnLk3qs8bcPQAAAFZ6VFh0U01JTEVTIHJka2l0IDIwMjQuMDkuNQAAeJxzdnZ2VqjR0DXUszS3NDPU0TXQMzQ2M9WxBjJMLS2NzS11DPRMTA0sjMx1rOFCuggxmEaoPs0aAMS3EPOswgaUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x1b76e6eb5f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('CCCC')\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7203a05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                         Name  \\\n",
      "0     1         Ibuprofen / HP-B-CD   \n",
      "1     2      Dexamethasone / B - CD   \n",
      "2     3         Piroxicam / HP-B-CD   \n",
      "3     4    Hydrocortisone / HP-B-CD   \n",
      "4     5       Albendazole / RM-B-CD   \n",
      "5     6            Valtarsan / B-CD   \n",
      "6     7        Nifedipine / HP-B-CD   \n",
      "7     8        Nimodipine / HP-B-CD   \n",
      "8     9     Carbamazepine / HP-B-CD   \n",
      "9    10      Itraconazole / HP-B-CD   \n",
      "10   11       Simvastatin / HP-B-CD   \n",
      "11   12          Curcumin / HP-B-CD   \n",
      "12   13  Indomethacin / HP- B - CD    \n",
      "13   14     Naproxen / HP - B - CD    \n",
      "14   15        Diclofenac / HP-B-CD   \n",
      "15   16   Resveratrol / HP-Gamma CD   \n",
      "\n",
      "                                               Smiles MolWeight   LogP  HBD  \\\n",
      "0                          CC(C)Cc1ccc(cc1)C(C)C(=O)O   1606.29 -1.641  NaN   \n",
      "1   CC(C)C1C(=O)CC2C(C1O)(CC(C1=CC(=O)C=C2C1(C)O)F...   1527.47 -1.560  NaN   \n",
      "2                     CN1NS(=O)(=O)C2=C(O)C=CN=C2C1=O   1466.35 -1.500  NaN   \n",
      "3              CC(=O)C1(CCC2C1(CCC1C(C2CC(C1O)O)O)C)O   1762.46 -1.520  NaN   \n",
      "4                      CCCSC1=CC=C2C=C1N=C(C(=O)OC)N2   250.323 -1.600  NaN   \n",
      "5   CC(C)C[C@H](C(=O)NCc1ccc(cc1)c1ccccc1C(=N)N=N)...    1570.5 -1.450  NaN   \n",
      "6   CCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])C)...      1846 -1.350  NaN   \n",
      "7   COCCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])...    418.44 -1.400  NaN   \n",
      "8                        O=C1Nc2ccccc2C2=CC=CC=C2C1=O  1371.25  -1.550  NaN   \n",
      "9   CC1=NC(C)=NC(OCC2CCC(OC3=NC(N4CCN(C)CC4)=NC(C4...    1840.6 -1.500  NaN   \n",
      "10  CC(C)CC(CC=C)C(=O)OC[C@@H]1CC[C@@H](CC1)C(=O)O...   1553.55 -1.450  NaN   \n",
      "11      COc1ccc(cc1)/C=C/C(=O)CC(=O)/C=C/c1ccc(cc1)OC   1503.36 -1.580  NaN   \n",
      "12      COc1ccc2c(c1)n(c(c2C(=O)O)C(=O)c1ccc(cc1)Cl)C    1492.8 -1.600  NaN   \n",
      "13                       COc1cc2ccc(C(C)C(=O)O)cc2cc1   1365.24 -1.480  NaN   \n",
      "14                   OC(=O)Cc1cccc(c1)Nc1c(cccc1Cl)Cl   1431.15 -1.650  NaN   \n",
      "15               OC1=CC=CC(/C=C/C2=CC(O)=CC(O)=C2)=C1   228.247    NaN  NaN   \n",
      "\n",
      "    HPCalculated  Descriptors   \\\n",
      "0            NaN           NaN   \n",
      "1            NaN           NaN   \n",
      "2            NaN           NaN   \n",
      "3            NaN           NaN   \n",
      "4            NaN           NaN   \n",
      "5            NaN           NaN   \n",
      "6            NaN           NaN   \n",
      "7            NaN           NaN   \n",
      "8            NaN           NaN   \n",
      "9            NaN           NaN   \n",
      "10           NaN           NaN   \n",
      "11           NaN           NaN   \n",
      "12           NaN           NaN   \n",
      "13           NaN           NaN   \n",
      "14           NaN           NaN   \n",
      "15           NaN           NaN   \n",
      "\n",
      "   CD-complex solubility (mg/ml; unless stated otherwise)  \\\n",
      "0                                                 NaN       \n",
      "1                                                 1.6       \n",
      "2                                                 0.1       \n",
      "3                                                  26       \n",
      "4                                                  30       \n",
      "5                                           1.2*10^-3       \n",
      "6                                               0.224       \n",
      "7                                               0.055       \n",
      "8                                                6.39       \n",
      "9                                          27000ng/mL       \n",
      "10                                               0.18       \n",
      "11                                                NaN       \n",
      "12                                                NaN       \n",
      "13                                             17.6mM       \n",
      "14                                             0.0225       \n",
      "15                                                1.1       \n",
      "\n",
      "   Intrinistic solubility (mg/ml; unless stated otherwise  Enhancement Factor  \n",
      "0                                                 NaN               30.000000  \n",
      "1                                                0.16               10.000000  \n",
      "2                                               0.023                4.347826  \n",
      "3                                                0.28               71.400000  \n",
      "4                                                0.01              600.000000  \n",
      "5                                    7.07*10^-6 mol/L              169.731259  \n",
      "6                                               0.005               44.800000  \n",
      "7                                              0.0025               22.000000  \n",
      "8                                                0.14               45.600000  \n",
      "9                                              1ng/mL            27000.000000  \n",
      "10                                               0.03                6.000000  \n",
      "11                                          0.6 ug/mL              206.000000  \n",
      "12                                          8.8 ug/mL               10.000000  \n",
      "13                                              0.5mM                5.866667  \n",
      "14                                              0.003                7.500000  \n",
      "15                                               0.03               36.666667  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:41:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "[17:41:47] DEPRECATION WARNING: please use MorganGenerator\n",
      "C:\\Users\\gagno\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 12, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 2337.723430\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "\n",
      "=== LightGBM Model (Test Set) ===\n",
      "n_estimators=100, learning_rate=0.1, random_state=42\n",
      "MSE  : 5218503.7710\n",
      "RMSE : 2284.4045\n",
      "MAE  : 2283.4156\n",
      "R²   : -1154.3289\n",
      "Adjusted R²: nan\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 16, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 1766.869526\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "\n",
      "=== Predict Enhancement Factor for a new SMILES ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a SMILES string (or type 'quit' to exit): quit\n",
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RDKit for SMILES parsing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Train-test split, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# (Optional) Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# LightGBM (install via: pip install lightgbm)\n",
    "import lightgbm as lgb\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=2, n_bits=256):\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to a Morgan fingerprint (ECFP) vector of length n_bits.\n",
    "    Returns a NumPy array of shape (n_bits,) or None if the SMILES is invalid.\n",
    "    \n",
    "    We use 256 bits (instead of 1024) to reduce dimensionality given the small dataset.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def main():\n",
    "    # 1. Load your CSV dataset (adjust filename/column names as needed)\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head(18))  # CSV should include 'SMILES', 'enhancement_factor', and 16 descriptor columns\n",
    "    \n",
    "    # 2. Basic cleaning: handle infinities and ensure 'Enhancement Factor' is numeric\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    \n",
    "    # Drop rows with missing values in critical columns\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    # 3. Convert SMILES to numeric features (Morgan fingerprints)\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    enhancement_factors = df[\"Enhancement Factor\"].values\n",
    "    \n",
    "    X_fps = []\n",
    "    valid_y = []\n",
    "    for smi, val in zip(smiles_list, enhancement_factors):\n",
    "        fp = smiles_to_morgan_fp(smi, radius=2, n_bits=256)\n",
    "        if fp is not None:\n",
    "            X_fps.append(fp)\n",
    "            valid_y.append(val)\n",
    "    X = np.array(X_fps, dtype=float)\n",
    "    y = np.array(valid_y, dtype=float)\n",
    "    \n",
    "    # 4. Train-test split\n",
    "    #    We'll do 80-20 here, but with only 16 rows, cross-validation is recommended.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # 5. (Optional) Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    \n",
    "    # 6. Define and train a LightGBM regressor\n",
    "    #    Adjust n_estimators, learning_rate, and other params via cross-validation if needed.\n",
    "    lgbm_reg = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgbm_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 7. Evaluate on the test set\n",
    "    y_pred = lgbm_reg.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adjusted R² = 1 - (1 - R²)*(n - 1)/(n - p - 1)\n",
    "    n = len(y_test)\n",
    "    p = X_test_scaled.shape[1]  # e.g., 256 if not reduced further\n",
    "    if n > p + 1:\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    else:\n",
    "        adjusted_r2 = float('nan')  # Not well-defined if p >= n-1\n",
    "    \n",
    "    print(\"\\n=== LightGBM Model (Test Set) ===\")\n",
    "    print(\"n_estimators=100, learning_rate=0.1, random_state=42\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    \n",
    "    # 8. Retrain on the entire dataset for new SMILES predictions\n",
    "    final_model = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    final_model.fit(X_scaled, y)\n",
    "    \n",
    "    # 9. Interactive input for new SMILES outside the dataset\n",
    "    print(\"\\n=== Predict Enhancement Factor for a new SMILES ===\")\n",
    "    while True:\n",
    "        user_input = input(\"Enter a SMILES string (or type 'quit' to exit): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "        \n",
    "        new_fp = smiles_to_morgan_fp(user_input, radius=2, n_bits=256)\n",
    "        if new_fp is None:\n",
    "            print(\"Invalid SMILES entered. Please try again.\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Scale the new fingerprint\n",
    "        new_fp_scaled = scaler.transform([new_fp])\n",
    "        pred_val = final_model.predict(new_fp_scaled)[0]\n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f543a38",
   "metadata": {},
   "source": [
    "Here is an improved version of algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ba6f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                         Name  \\\n",
      "0     1         Ibuprofen / HP-B-CD   \n",
      "1     2      Dexamethasone / B - CD   \n",
      "2     3         Piroxicam / HP-B-CD   \n",
      "3     4    Hydrocortisone / HP-B-CD   \n",
      "4     5       Albendazole / RM-B-CD   \n",
      "5     6            Valtarsan / B-CD   \n",
      "6     7        Nifedipine / HP-B-CD   \n",
      "7     8        Nimodipine / HP-B-CD   \n",
      "8     9     Carbamazepine / HP-B-CD   \n",
      "9    10      Itraconazole / HP-B-CD   \n",
      "10   11       Simvastatin / HP-B-CD   \n",
      "11   12          Curcumin / HP-B-CD   \n",
      "12   13  Indomethacin / HP- B - CD    \n",
      "13   14     Naproxen / HP - B - CD    \n",
      "14   15        Diclofenac / HP-B-CD   \n",
      "15   16   Resveratrol / HP-Gamma CD   \n",
      "16   17              Amphotericin B   \n",
      "17   18                 Budesonide    \n",
      "\n",
      "                                               Smiles MolWeight  LogP  \\\n",
      "0                          CC(C)Cc1ccc(cc1)C(C)C(=O)O   1606.29  3.84   \n",
      "1   CC(C)C1C(=O)CC2C(C1O)(CC(C1=CC(=O)C=C2C1(C)O)F...   1527.47  1.93   \n",
      "2                     CN1NS(=O)(=O)C2=C(O)C=CN=C2C1=O   1466.35   2.2   \n",
      "3              CC(=O)C1(CCC2C1(CCC1C(C2CC(C1O)O)O)C)O   1762.46  1.79   \n",
      "4                      CCCSC1=CC=C2C=C1N=C(C(=O)OC)N2   250.323  3.22   \n",
      "5   CC(C)C[C@H](C(=O)NCc1ccc(cc1)c1ccccc1C(=N)N=N)...    1570.5  3.68   \n",
      "6   CCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])C)...      1846  2.49   \n",
      "7   COCCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])...    418.44  3.41   \n",
      "8                        O=C1Nc2ccccc2C2=CC=CC=C2C1=O  1371.25    2.1   \n",
      "9   CC1=NC(C)=NC(OCC2CCC(OC3=NC(N4CCN(C)CC4)=NC(C4...    1840.6  5.48   \n",
      "10  CC(C)CC(CC=C)C(=O)OC[C@@H]1CC[C@@H](CC1)C(=O)O...   1553.55  4.51   \n",
      "11      COc1ccc(cc1)/C=C/C(=O)CC(=O)/C=C/c1ccc(cc1)OC   1503.36  3.62   \n",
      "12      COc1ccc2c(c1)n(c(c2C(=O)O)C(=O)c1ccc(cc1)Cl)C    1492.8  4.46   \n",
      "13                       COc1cc2ccc(C(C)C(=O)O)cc2cc1   1365.24  3.39   \n",
      "14                   OC(=O)Cc1cccc(c1)Nc1c(cccc1Cl)Cl   1431.15  4.75   \n",
      "15               OC1=CC=CC(/C=C/C2=CC(O)=CC(O)=C2)=C1  1728.247  2.57   \n",
      "16  CC(C)CCCC(C)CCCC(C)C(C)CCC/C=C\\C/C=C\\C/C=C\\C/C...         -     -   \n",
      "17  CC(=CC(=O)C12CCC(C)CC1CCC1C2CCC2OC(C)(C)CC1(C)...         -     -   \n",
      "\n",
      "       LogS (CD)  HPCalculated  Descriptors   \\\n",
      "0           -3.5           NaN           NaN   \n",
      "1    2.979852707           NaN           NaN   \n",
      "2    4.166237644           NaN           NaN   \n",
      "3    1.831145921           NaN           NaN   \n",
      "4      0.9213795           NaN           NaN   \n",
      "5    2.920818754           NaN           NaN   \n",
      "6    3.915983678           NaN           NaN   \n",
      "7    3.881270504           NaN           NaN   \n",
      "8   -2.331615782           NaN           NaN   \n",
      "9    4.833595654           NaN           NaN   \n",
      "10    3.93605273           NaN           NaN   \n",
      "11    4.08504452           NaN           NaN   \n",
      "12   4.229518954           NaN           NaN   \n",
      "13   1.754487332           NaN           NaN   \n",
      "14   4.803502637           NaN           NaN   \n",
      "15   3.196213127           NaN           NaN   \n",
      "16             -           NaN           NaN   \n",
      "17             -           NaN           NaN   \n",
      "\n",
      "    CD-complex solubility (mg/ml; unless stated otherwise)  \\\n",
      "0                                                 NaN        \n",
      "1                                            1.600000        \n",
      "2                                            0.100000        \n",
      "3                                           26.000000        \n",
      "4                                           30.000000        \n",
      "5                                            1.884600        \n",
      "6                                            0.224000        \n",
      "7                                            0.055000        \n",
      "8                                            6.390000        \n",
      "9                                            0.027000        \n",
      "10                                           0.180000        \n",
      "11                                           0.123600        \n",
      "12                                           0.088000        \n",
      "13                                          24.028224        \n",
      "14                                           0.022500        \n",
      "15                                           1.100000        \n",
      "16                                           0.150000        \n",
      "17                                           0.845000        \n",
      "\n",
      "    Intrinistic solubility (mg/ml; unless stated otherwise  Enhancement Factor  \n",
      "0                                                 NaN                30.000000  \n",
      "1                                            0.160000                10.000000  \n",
      "2                                            0.023000                 4.347826  \n",
      "3                                            0.280000                71.400000  \n",
      "4                                            0.010000               600.000000  \n",
      "5                                            0.003192               590.783000  \n",
      "6                                            0.005000                44.800000  \n",
      "7                                            0.002500                22.000000  \n",
      "8                                            0.140000                45.600000  \n",
      "9                                            0.000001             27000.000000  \n",
      "10                                           0.030000                 6.000000  \n",
      "11                                           0.000600               206.000000  \n",
      "12                                           0.008800                10.000000  \n",
      "13                                           0.115131               208.704900  \n",
      "14                                           0.003000                 7.500000  \n",
      "15                                           0.030000                36.666667  \n",
      "16                                           0.001000               150.000000  \n",
      "17                                           0.022000                38.409091  \n",
      "Unique rows in X: 51\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 40, number of used features: 250\n",
      "[LightGBM] [Info] Start training from score 1814.221882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n",
      "[23:54:46] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "\n",
      "=== LightGBM Model (Test Set) ===\n",
      "With min_data_in_leaf=1, min_data_in_bin=1\n",
      "MSE  : 211589.1068\n",
      "RMSE : 459.9882\n",
      "MAE  : 299.8526\n",
      "R²   : -0.7274\n",
      "Adjusted R²: nan\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 51, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 1459.408718\n",
      "\n",
      "Enter SMILES (or 'quit'): quit\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=2, n_bits=256):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def main():\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head(18))  # CSV should include 'SMILES', 'enhancement_factor', and 16 descriptor columns\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    # Convert SMILES to fingerprints\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    enhancement_factors = df[\"Enhancement Factor\"].values\n",
    "    \n",
    "    X_fps = []\n",
    "    valid_y = []\n",
    "    for smi, val in zip(smiles_list, enhancement_factors):\n",
    "        fp = smiles_to_morgan_fp(smi, radius=2, n_bits=256)\n",
    "        if fp is not None:\n",
    "            X_fps.append(fp)\n",
    "            valid_y.append(val)\n",
    "    \n",
    "    X = np.array(X_fps, dtype=float)\n",
    "    y = np.array(valid_y, dtype=float)\n",
    "\n",
    "    # Quick check: are all fingerprints identical?\n",
    "    print(\"Unique rows in X:\", np.unique(X, axis=0).shape[0])\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Optional scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    # LightGBM with relaxed leaf/bins\n",
    "    lgbm_reg = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        min_data_in_leaf=1,  # was 20 by default\n",
    "        min_data_in_bin=1    # reduce bin constraints\n",
    "    )\n",
    "    lgbm_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = lgbm_reg.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    n = len(y_test)\n",
    "    p = X_test_scaled.shape[1]\n",
    "    if n > p + 1:\n",
    "        adjusted_r2 = 1 - (1 - r2)*(n - 1)/(n - p - 1)\n",
    "    else:\n",
    "        adjusted_r2 = float('nan')\n",
    "\n",
    "    print(\"\\n=== LightGBM Model (Test Set) ===\")\n",
    "    print(\"With min_data_in_leaf=1, min_data_in_bin=1\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "\n",
    "    # Retrain on all data\n",
    "    final_model = lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        min_data_in_leaf=1,\n",
    "        min_data_in_bin=1\n",
    "    )\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    final_model.fit(X_scaled, y)\n",
    "\n",
    "    # Predict new SMILES\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter SMILES (or 'quit'): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        new_fp = smiles_to_morgan_fp(user_input, radius=2, n_bits=256)\n",
    "        if new_fp is None:\n",
    "            print(\"Invalid SMILES. Try again.\")\n",
    "            continue\n",
    "        new_fp_scaled = scaler.transform([new_fp])\n",
    "        pred_val = final_model.predict(new_fp_scaled)[0]\n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3d9a0",
   "metadata": {},
   "source": [
    "Here is much more imrpoved version even\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n",
    "=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa83f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded. Shape: (51, 11)\n",
      "Enhancement Factor range: 0.221698113 to 27000.0\n",
      "Generating molecular features...\n",
      "Features generated. X shape: (51, 1036)\n",
      "After removing constant features: (51, 893)\n",
      "Optimizing hyperparameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:04:43] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'min_child_samples': 5, 'n_estimators': 50, 'num_leaves': 7, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'subsample': 0.8}\n",
      "Cross-validation R² scores: [-0.05044144 -4.01870591 -1.05792887 -0.07624155 -0.89330797]\n",
      "Mean CV R²: -1.2193 ± 1.4589\n",
      "\n",
      "=== LightGBM Model (Test Set) ===\n",
      "Log-transformed space:\n",
      "MSE  : 6.8503\n",
      "RMSE : 2.6173\n",
      "MAE  : 1.9991\n",
      "R²   : 0.0206\n",
      "\n",
      "Original space:\n",
      "MSE  : 52332066.6619\n",
      "RMSE : 7234.0906\n",
      "MAE  : 2271.1179\n",
      "R²   : -0.1054\n",
      "Top 1 feature (Feature_891): 36\n",
      "Top 2 feature (Feature_884): 28\n",
      "Top 3 feature (Feature_882): 23\n",
      "Top 4 feature (Feature_585): 20\n",
      "Top 5 feature (Feature_889): 19\n",
      "Top 6 feature (Feature_881): 19\n",
      "Top 7 feature (Feature_886): 16\n",
      "Top 8 feature (Feature_149): 15\n",
      "Top 9 feature (Feature_474): 14\n",
      "Top 10 feature (Feature_303): 10\n",
      "Top 11 feature (Feature_892): 9\n",
      "Top 12 feature (Feature_883): 9\n",
      "Top 13 feature (Feature_416): 7\n",
      "Top 14 feature (Feature_257): 7\n",
      "Top 15 feature (Feature_82): 5\n",
      "Top 16 feature (Feature_370): 5\n",
      "Top 17 feature (Feature_53): 4\n",
      "Top 18 feature (Feature_888): 4\n",
      "Top 19 feature (Feature_113): 3\n",
      "Top 20 feature (Feature_393): 3\n",
      "\n",
      "Training final model on all data...\n",
      "\n",
      "Model ready for predictions!\n",
      "\n",
      "Enter SMILES (or 'quit'): quit\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Lipinski\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=3, n_bits=1024):\n",
    "    \"\"\"Convert SMILES to Morgan fingerprint with more bits and larger radius\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def calculate_additional_descriptors(smi):\n",
    "    \"\"\"Calculate additional molecular descriptors to enrich the model\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    descriptors = []\n",
    "    \n",
    "    # Basic properties\n",
    "    descriptors.append(Descriptors.MolWt(mol))             # Molecular weight\n",
    "    descriptors.append(Descriptors.MolLogP(mol))           # LogP\n",
    "    descriptors.append(Descriptors.TPSA(mol))              # Topological polar surface area\n",
    "    \n",
    "    # Hydrogen bond features\n",
    "    descriptors.append(Lipinski.NumHDonors(mol))           # H-bond donors\n",
    "    descriptors.append(Lipinski.NumHAcceptors(mol))        # H-bond acceptors\n",
    "    \n",
    "    # Structural features\n",
    "    descriptors.append(Descriptors.NumRotatableBonds(mol)) # Rotatable bonds\n",
    "    descriptors.append(Descriptors.NumAromaticRings(mol))  # Aromatic rings\n",
    "    descriptors.append(Descriptors.NumHeteroatoms(mol))    # Number of heteroatoms\n",
    "    descriptors.append(Descriptors.FractionCSP3(mol))      # Fraction of sp3 carbons\n",
    "    \n",
    "    # Electronic properties\n",
    "    descriptors.append(Descriptors.NumRadicalElectrons(mol)) # Radical electrons\n",
    "    descriptors.append(Descriptors.MaxPartialCharge(mol) if hasattr(Descriptors, 'MaxPartialCharge') else 0)\n",
    "    descriptors.append(Descriptors.MinPartialCharge(mol) if hasattr(Descriptors, 'MinPartialCharge') else 0)\n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "def main():\n",
    "    print(\"Loading dataset...\")\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Clean data\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "    print(f\"Enhancement Factor range: {df['Enhancement Factor'].min()} to {df['Enhancement Factor'].max()}\")\n",
    "    \n",
    "    # Transform target to log scale to handle wide range of values\n",
    "    y_original = df[\"Enhancement Factor\"].values\n",
    "    y = np.log1p(y_original)  # Log transform for better handling of wide range\n",
    "    \n",
    "    # Extract features\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    \n",
    "    # Prepare feature matrix with both fingerprints and descriptors\n",
    "    X_combined = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    print(\"Generating molecular features...\")\n",
    "    for i, smi in enumerate(smiles_list):\n",
    "        # Get Morgan fingerprint\n",
    "        fp = smiles_to_morgan_fp(smi, radius=3, n_bits=1024)\n",
    "        \n",
    "        # Get additional descriptors\n",
    "        descriptors = calculate_additional_descriptors(smi)\n",
    "        \n",
    "        if fp is not None and descriptors is not None:\n",
    "            features = np.concatenate([fp, descriptors])\n",
    "            X_combined.append(features)\n",
    "            valid_indices.append(i)\n",
    "    \n",
    "    X = np.array(X_combined, dtype=float)\n",
    "    y = y[valid_indices]  # Keep only valid molecules\n",
    "    y_original = y_original[valid_indices]\n",
    "    \n",
    "    print(f\"Features generated. X shape: {X.shape}\")\n",
    "    \n",
    "    # Feature selection - removing constant features\n",
    "    non_constant_cols = np.where(X.std(axis=0) > 0)[0]\n",
    "    X = X[:, non_constant_cols]\n",
    "    print(f\"After removing constant features: {X.shape}\")\n",
    "    \n",
    "    # Train-test split with stratification based on binned target values\n",
    "    y_bins = pd.qcut(y, q=5, labels=False, duplicates='drop')\n",
    "    X_train, X_test, y_train, y_test, y_orig_train, y_orig_test = train_test_split(\n",
    "        X, y, y_original, test_size=0.2, random_state=42, stratify=y_bins\n",
    "    )\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Hyperparameter optimization using Grid Search\n",
    "    print(\"Optimizing hyperparameters...\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [7, 15, 31],\n",
    "        'min_child_samples': [1, 3, 5],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 0.5],\n",
    "        'reg_lambda': [0, 0.1, 0.5]\n",
    "    }\n",
    "    \n",
    "    lgbm_base = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Use 5-fold cross-validation for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lgbm_base,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    lgbm_reg = lgb.LGBMRegressor(\n",
    "        **best_params,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation assessment\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(\n",
    "        lgbm_reg, X_train_scaled, y_train, \n",
    "        cv=cv, scoring='r2', n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f\"Cross-validation R² scores: {cv_scores}\")\n",
    "    print(f\"Mean CV R²: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Train final model on all training data\n",
    "    lgbm_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set (log-transformed space)\n",
    "    y_pred_log = lgbm_reg.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert predictions back to original scale\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    \n",
    "    # Evaluate on both scales\n",
    "    # Log-transformed scale metrics\n",
    "    mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "    rmse_log = np.sqrt(mse_log)\n",
    "    mae_log = mean_absolute_error(y_test, y_pred_log)\n",
    "    r2_log = r2_score(y_test, y_pred_log)\n",
    "    \n",
    "    # Original scale metrics\n",
    "    mse = mean_squared_error(y_orig_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_orig_test, y_pred)\n",
    "    r2 = r2_score(y_orig_test, y_pred)\n",
    "    \n",
    "    print(\"\\n=== LightGBM Model (Test Set) ===\")\n",
    "    print(f\"Log-transformed space:\")\n",
    "    print(f\"MSE  : {mse_log:.4f}\")\n",
    "    print(f\"RMSE : {rmse_log:.4f}\")\n",
    "    print(f\"MAE  : {mae_log:.4f}\")\n",
    "    print(f\"R²   : {r2_log:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOriginal space:\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = lgbm_reg.feature_importances_\n",
    "    top_indices = importance.argsort()[-20:][::-1]  # Get top 20 features\n",
    "    \n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        print(f\"Top {i+1} feature ({feature_names[idx]}): {importance[idx]}\")\n",
    "    \n",
    "    # Visualization of predictions vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_orig_test, y_pred, alpha=0.7)\n",
    "    plt.plot([min(y_orig_test), max(y_orig_test)], [min(y_orig_test), max(y_orig_test)], 'r--')\n",
    "    plt.xlabel('Actual Enhancement Factor')\n",
    "    plt.ylabel('Predicted Enhancement Factor')\n",
    "    plt.title('LGBM Model: Actual vs Predicted Enhancement Factor')\n",
    "    plt.savefig('prediction_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Retrain on all data for deployment\n",
    "    print(\"\\nTraining final model on all data...\")\n",
    "    X_all_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    final_model = lgb.LGBMRegressor(\n",
    "        **best_params,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    final_model.fit(X_all_scaled, y)\n",
    "    \n",
    "    # Prediction interface\n",
    "    print(\"\\nModel ready for predictions!\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter SMILES (or 'quit'): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        # Process new molecule\n",
    "        new_fp = smiles_to_morgan_fp(user_input, radius=3, n_bits=1024)\n",
    "        new_descriptors = calculate_additional_descriptors(user_input)\n",
    "        \n",
    "        if new_fp is None or new_descriptors is None:\n",
    "            print(\"Invalid SMILES. Try again.\")\n",
    "            continue\n",
    "            \n",
    "        new_features = np.concatenate([new_fp, new_descriptors])\n",
    "        new_features = new_features[non_constant_cols]  # Apply same feature selection\n",
    "        new_features_scaled = scaler.transform([new_features])\n",
    "        \n",
    "        # Predict in log space then convert back\n",
    "        pred_log = final_model.predict(new_features_scaled)[0]\n",
    "        pred_val = np.expm1(pred_log)\n",
    "        \n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24526c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
