{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad4bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2024.9.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from rdkit) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from rdkit) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gagno\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\gagno\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\gagno\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\gagno\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: ngboost in c:\\users\\gagno\\anaconda3\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: scipy>=1.7.2 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from ngboost) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.6 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from ngboost) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from ngboost) (1.24.4)\n",
      "Requirement already satisfied: lifelines>=0.25 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from ngboost) (0.30.0)\n",
      "Requirement already satisfied: tqdm>=4.3 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from ngboost) (4.64.1)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (1.1.1)\n",
      "Requirement already satisfied: autograd>=1.5 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (1.7.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (0.5.0)\n",
      "Requirement already satisfied: pandas>=2.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from lifelines>=0.25->ngboost) (3.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn<2.0,>=1.6->ngboost) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from scikit-learn<2.0,>=1.6->ngboost) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from tqdm>=4.3->ngboost) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.3.0)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.25.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gagno\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install joblib\n",
    "!pip install ngboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2c2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca1efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x20e93498660>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('CCCC')\n",
    "mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f224b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                         Name  \\\n",
      "0     1         Ibuprofen / HP-B-CD   \n",
      "1     2      Dexamethasone / B - CD   \n",
      "2     3         Piroxicam / HP-B-CD   \n",
      "3     4    Hydrocortisone / HP-B-CD   \n",
      "4     5       Albendazole / RM-B-CD   \n",
      "5     6            Valtarsan / B-CD   \n",
      "6     7        Nifedipine / HP-B-CD   \n",
      "7     8        Nimodipine / HP-B-CD   \n",
      "8     9     Carbamazepine / HP-B-CD   \n",
      "9    10      Itraconazole / HP-B-CD   \n",
      "10   11       Simvastatin / HP-B-CD   \n",
      "11   12          Curcumin / HP-B-CD   \n",
      "12   13  Indomethacin / HP- B - CD    \n",
      "13   14     Naproxen / HP - B - CD    \n",
      "14   15        Diclofenac / HP-B-CD   \n",
      "15   16   Resveratrol / HP-Gamma CD   \n",
      "16   17              Amphotericin B   \n",
      "17   18                 Budesonide    \n",
      "\n",
      "                                               Smiles MolWeight  LogP  \\\n",
      "0                          CC(C)Cc1ccc(cc1)C(C)C(=O)O   1606.29  3.84   \n",
      "1   CC(C)C1C(=O)CC2C(C1O)(CC(C1=CC(=O)C=C2C1(C)O)F...   1527.47  1.93   \n",
      "2                     CN1NS(=O)(=O)C2=C(O)C=CN=C2C1=O   1466.35   2.2   \n",
      "3              CC(=O)C1(CCC2C1(CCC1C(C2CC(C1O)O)O)C)O   1762.46  1.79   \n",
      "4                      CCCSC1=CC=C2C=C1N=C(C(=O)OC)N2   250.323  3.22   \n",
      "5   CC(C)C[C@H](C(=O)NCc1ccc(cc1)c1ccccc1C(=N)N=N)...    1570.5  3.68   \n",
      "6   CCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])C)...      1846  2.49   \n",
      "7   COCCOC(=O)C1=C(C)NC(=C(C1c1ccccc1[N+](=O)[O-])...    418.44  3.41   \n",
      "8                        O=C1Nc2ccccc2C2=CC=CC=C2C1=O  1371.25    2.1   \n",
      "9   CC1=NC(C)=NC(OCC2CCC(OC3=NC(N4CCN(C)CC4)=NC(C4...    1840.6  5.48   \n",
      "10  CC(C)CC(CC=C)C(=O)OC[C@@H]1CC[C@@H](CC1)C(=O)O...   1553.55  4.51   \n",
      "11      COc1ccc(cc1)/C=C/C(=O)CC(=O)/C=C/c1ccc(cc1)OC   1503.36  3.62   \n",
      "12      COc1ccc2c(c1)n(c(c2C(=O)O)C(=O)c1ccc(cc1)Cl)C    1492.8  4.46   \n",
      "13                       COc1cc2ccc(C(C)C(=O)O)cc2cc1   1365.24  3.39   \n",
      "14                   OC(=O)Cc1cccc(c1)Nc1c(cccc1Cl)Cl   1431.15  4.75   \n",
      "15               OC1=CC=CC(/C=C/C2=CC(O)=CC(O)=C2)=C1  1728.247  2.57   \n",
      "16  CC(C)CCCC(C)CCCC(C)C(C)CCC/C=C\\C/C=C\\C/C=C\\C/C...         -     -   \n",
      "17  CC(=CC(=O)C12CCC(C)CC1CCC1C2CCC2OC(C)(C)CC1(C)...         -     -   \n",
      "\n",
      "       LogS (CD)  HPCalculated  Descriptors   \\\n",
      "0           -3.5           NaN           NaN   \n",
      "1    2.979852707           NaN           NaN   \n",
      "2    4.166237644           NaN           NaN   \n",
      "3    1.831145921           NaN           NaN   \n",
      "4      0.9213795           NaN           NaN   \n",
      "5    2.920818754           NaN           NaN   \n",
      "6    3.915983678           NaN           NaN   \n",
      "7    3.881270504           NaN           NaN   \n",
      "8   -2.331615782           NaN           NaN   \n",
      "9    4.833595654           NaN           NaN   \n",
      "10    3.93605273           NaN           NaN   \n",
      "11    4.08504452           NaN           NaN   \n",
      "12   4.229518954           NaN           NaN   \n",
      "13   1.754487332           NaN           NaN   \n",
      "14   4.803502637           NaN           NaN   \n",
      "15   3.196213127           NaN           NaN   \n",
      "16             -           NaN           NaN   \n",
      "17             -           NaN           NaN   \n",
      "\n",
      "    CD-complex solubility (mg/ml; unless stated otherwise)  \\\n",
      "0                                                 NaN        \n",
      "1                                            1.600000        \n",
      "2                                            0.100000        \n",
      "3                                           26.000000        \n",
      "4                                           30.000000        \n",
      "5                                            1.884600        \n",
      "6                                            0.224000        \n",
      "7                                            0.055000        \n",
      "8                                            6.390000        \n",
      "9                                            0.027000        \n",
      "10                                           0.180000        \n",
      "11                                           0.123600        \n",
      "12                                           0.088000        \n",
      "13                                          24.028224        \n",
      "14                                           0.022500        \n",
      "15                                           1.100000        \n",
      "16                                           0.150000        \n",
      "17                                           0.845000        \n",
      "\n",
      "    Intrinistic solubility (mg/ml; unless stated otherwise  Enhancement Factor  \n",
      "0                                                 NaN                30.000000  \n",
      "1                                            0.160000                10.000000  \n",
      "2                                            0.023000                 4.347826  \n",
      "3                                            0.280000                71.400000  \n",
      "4                                            0.010000               600.000000  \n",
      "5                                            0.003192               590.783000  \n",
      "6                                            0.005000                44.800000  \n",
      "7                                            0.002500                22.000000  \n",
      "8                                            0.140000                45.600000  \n",
      "9                                            0.000001             27000.000000  \n",
      "10                                           0.030000                 6.000000  \n",
      "11                                           0.000600               206.000000  \n",
      "12                                           0.008800                10.000000  \n",
      "13                                           0.115131               208.704900  \n",
      "14                                           0.003000                 7.500000  \n",
      "15                                           0.030000                36.666667  \n",
      "16                                           0.001000               150.000000  \n",
      "17                                           0.022000                38.409091  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n",
      "[00:16:06] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "check_X_y() got an unexpected keyword argument 'ensure_all_finite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24596\\3373661645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24596\\3373661645.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     )\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mngb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# 7. Predict on the test set in log space, then exponentiate back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ngboost\\ngboost.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         return self.partial_fit(\n\u001b[0m\u001b[0;32m    255\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ngboost\\ngboost.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         X, Y = check_X_y(\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: check_X_y() got an unexpected keyword argument 'ensure_all_finite'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RDKit for SMILES parsing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Train-test split, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# NGBoost\n",
    "# pip install ngboost\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import MLE\n",
    "\n",
    "# (Optional) Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def smiles_to_morgan_fp(smi, radius=2, n_bits=256):\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to a Morgan fingerprint (ECFP) vector of length n_bits.\n",
    "    Returns a NumPy array of shape (n_bits,) or None if SMILES is invalid.\n",
    "\n",
    "    Reduced from 1024 to 256 bits to lower dimensionality\n",
    "    and help avoid overfitting on a small dataset.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    for i in range(n_bits):\n",
    "        if fp.GetBit(i):\n",
    "            arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def main():\n",
    "    # 1. Load your CSV dataset (adjust filename/columns if needed)\n",
    "    file_path = 'C:/Users/gagno/Downloads/molecule_dataset.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head(18))  # CSV should include 'Smiles' and 'Enhancement Factor' columns\n",
    "    \n",
    "    # 2. Basic cleaning: handle infinities and ensure 'Enhancement Factor' is numeric\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df[\"Enhancement Factor\"] = pd.to_numeric(df[\"Enhancement Factor\"], errors='coerce')\n",
    "    \n",
    "    # Drop rows with missing values in 'Smiles' or 'Enhancement Factor'\n",
    "    df.dropna(subset=[\"Smiles\", \"Enhancement Factor\"], inplace=True)\n",
    "    \n",
    "    # 3. Convert SMILES to numeric features (Morgan fingerprints)\n",
    "    smiles_list = df[\"Smiles\"].astype(str).tolist()\n",
    "    enhancement_factors = df[\"Enhancement Factor\"].values\n",
    "    \n",
    "    X_fps = []\n",
    "    valid_y = []\n",
    "    for smi, val in zip(smiles_list, enhancement_factors):\n",
    "        fp = smiles_to_morgan_fp(smi, radius=2, n_bits=256)\n",
    "        if fp is not None:\n",
    "            X_fps.append(fp)\n",
    "            valid_y.append(val)\n",
    "    \n",
    "    X = np.array(X_fps, dtype=float)\n",
    "    y = np.array(valid_y, dtype=float)\n",
    "    \n",
    "    # 4. Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # --- NEW: Log-Transform the Target ---\n",
    "    # We'll transform y_train and y_test so that the model predicts log(EF).\n",
    "    # This can drastically reduce MSE if EF spans multiple orders of magnitude.\n",
    "    y_train_log = np.log1p(y_train)  # log(1 + EF)\n",
    "    y_test_log  = np.log1p(y_test)\n",
    "    \n",
    "    # 5. (Optional) Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "    \n",
    "    # 6. Define and train an NGBoost regressor\n",
    "    #    We'll keep the same hyperparams but now the model sees log(EF).\n",
    "    ngb = NGBRegressor(\n",
    "        Dist=Normal,\n",
    "        Score=MLE,           # important: do not use MLE()\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    ngb.fit(X_train_scaled, y_train_log)\n",
    "    \n",
    "    # 7. Predict on the test set in log space, then exponentiate back\n",
    "    y_pred_log = ngb.predict(X_test_scaled)\n",
    "    y_pred = np.expm1(y_pred_log)  # revert from log(EF) to EF\n",
    "    \n",
    "    # 8. Compute evaluation metrics on original EF scale\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adjusted R²\n",
    "    n = len(y_test)\n",
    "    p = X_test_scaled.shape[1]\n",
    "    if n > p + 1:\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    else:\n",
    "        adjusted_r2 = float('nan')\n",
    "    \n",
    "    print(\"\\n=== NGBoost Model (Test Set) ===\")\n",
    "    print(\"Distribution: Normal, Score=MLE, learning_rate=0.01, n_estimators=500\")\n",
    "    print(\"Log transform of Enhancement Factor + 256-bit fingerprints\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"R²   : {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    \n",
    "    # 9. (Optional) Predict new SMILES\n",
    "    print(\"\\n=== Predict Enhancement Factor for a new SMILES ===\")\n",
    "    while True:\n",
    "        user_input = input(\"Enter a SMILES string (or type 'quit' to exit): \").strip()\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "        \n",
    "        new_fp = smiles_to_morgan_fp(user_input, radius=2, n_bits=256)\n",
    "        if new_fp is None:\n",
    "            print(\"Invalid SMILES entered. Please try again.\\n\")\n",
    "            continue\n",
    "        \n",
    "        # Scale\n",
    "        new_fp_scaled = scaler.transform([new_fp])\n",
    "        # Predict in log space, then exponentiate\n",
    "        pred_log = ngb.predict(new_fp_scaled)[0]\n",
    "        pred_val = np.expm1(pred_log)\n",
    "        print(f\"Predicted Enhancement Factor: {pred_val:.4f}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56c172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
